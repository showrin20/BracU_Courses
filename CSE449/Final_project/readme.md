# Federated Learning with Transformer Models on Mobile Devices

## Project Overview
This project explores the implementation of Federated Learning using Transformer models on mobile devices. The goal is to leverage the power of distributed learning while maintaining data privacy, making it suitable for applications that require sensitive data handling.


## Project Idea
You can find a detailed description of the project idea [here](https://docs.google.com/document/d/1EgUlcfFL9RSYfDEKR-1rMqvcPgLqxgRmVrwU4C35V8M/edit?usp=sharing).

## Exploratory Data Analysis (EDA)
The EDA for this project is conducted using a dataset available on Kaggle. The analysis and insights can be found [here](https://www.kaggle.com/code/showrinrahman/notebookb2c6260e09/edit).

### EDA Presentation
The results of the EDA are summarized in the presentation [here](https://docs.google.com/presentation/d/1e43Hvgp6AYmG-GnqcCL6yP77EXaAABwAgjOxyXxcVAg/edit#slide=id.p).

## Project Code
The code for this project is available in the repository. Please check the respective files and directories to explore the implementation details.

## Final Presentation
You can view the final presentation summarizing the project objectives, methodologies, and results [here](https://docs.google.com/presentation/d/1UzVDS02cYhli7bLyVVJuP2joeKGh1SSunuqT4-eYg68/edit?usp=sharing).

## Final Report
The final report is [here](#)
